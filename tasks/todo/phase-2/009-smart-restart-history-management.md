---
phase: 2
order: 9
source_plan: /tasks/plan/phase2-advanced-features.md
priority: medium
tags: [smart-restart, history-management, statistics]
estimated_days: 2
depends_on: [008-smart-restart-execution-tracker]
---

# ğŸ“Œ ì‘ì—…: ìŠ¤ë§ˆíŠ¸ ì¬ì‹œì‘ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ

## ğŸ¯ ëª©í‘œ
ì‹¤í–‰ íˆìŠ¤í† ë¦¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ì„±ê³µ/ì‹¤íŒ¨ í†µê³„ë¥¼ ì œê³µí•˜ë©°, íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ ì‘ì—… ë‚´ìš©

### 1. íˆìŠ¤í† ë¦¬ ëª…ë ¹ì–´ êµ¬í˜„
```python
# sbkube/commands/history.py
import click
import sys
from typing import List, Dict, Any
from datetime import datetime, timedelta
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, BarColumn, TextColumn, TimeElapsedColumn

from sbkube.utils.execution_tracker import ExecutionTracker
from sbkube.utils.logger import logger
from sbkube.models.execution_state import StepStatus

console = Console()

@click.command(name="history")
@click.option("--limit", default=10, help="í‘œì‹œí•  íˆìŠ¤í† ë¦¬ ê°œìˆ˜ (ê¸°ë³¸ê°’: 10)")
@click.option("--detailed", is_flag=True, help="ìƒì„¸ ì •ë³´ í‘œì‹œ")
@click.option("--failures", is_flag=True, help="ì‹¤íŒ¨í•œ ì‹¤í–‰ë§Œ í‘œì‹œ")
@click.option("--profile", help="íŠ¹ì • í”„ë¡œíŒŒì¼ì˜ íˆìŠ¤í† ë¦¬ë§Œ í‘œì‹œ")
@click.option("--clean", is_flag=True, help="ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ ì •ë¦¬")
@click.option("--stats", is_flag=True, help="í†µê³„ ì •ë³´ í‘œì‹œ")
@click.pass_context
def cmd(ctx, limit, detailed, failures, profile, clean, stats):
    """ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ë° ê´€ë¦¬
    
    ìµœê·¼ ì‹¤í–‰ ê¸°ë¡ì„ ì¡°íšŒí•˜ê³  ì„±ê³µ/ì‹¤íŒ¨ í†µê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    \\b
    ì‚¬ìš© ì˜ˆì‹œ:
        sbkube history                    # ìµœê·¼ 10ê°œ ì‹¤í–‰ ê¸°ë¡
        sbkube history --detailed         # ìƒì„¸ ì •ë³´ í¬í•¨
        sbkube history --failures         # ì‹¤íŒ¨í•œ ì‹¤í–‰ë§Œ í‘œì‹œ
        sbkube history --stats            # í†µê³„ ì •ë³´ í‘œì‹œ
        sbkube history --clean            # ì˜¤ë˜ëœ ê¸°ë¡ ì •ë¦¬
    """
    
    try:
        tracker = ExecutionTracker(".", profile)
        
        if clean:
            _clean_old_history(tracker)
            return
        
        if stats:
            _show_statistics(tracker)
            return
        
        history = tracker.load_execution_history(limit)
        
        if failures:
            history = [h for h in history if h['status'] == 'failed']
        
        if profile:
            history = [h for h in history if h.get('profile') == profile]
        
        if not history:
            console.print("ğŸ“‹ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if detailed:
            _show_detailed_history(history)
        else:
            _show_simple_history(history)
            
    except Exception as e:
        logger.error(f"âŒ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)

def _show_simple_history(history: List[Dict[str, Any]]):
    """ê°„ë‹¨í•œ íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
    table = Table(title="ğŸ“‹ ìµœê·¼ ì‹¤í–‰ íˆìŠ¤í† ë¦¬")
    table.add_column("Run ID", style="cyan", width=10)
    table.add_column("í”„ë¡œíŒŒì¼", style="blue")
    table.add_column("ìƒíƒœ", justify="center")
    table.add_column("ì‹œì‘ ì‹œê°„", style="dim")
    table.add_column("ì†Œìš” ì‹œê°„", justify="right")
    
    for record in history:
        # ìƒíƒœ ì•„ì´ì½˜
        status_icon = {
            'completed': 'âœ…',
            'failed': 'âŒ',
            'in_progress': 'ğŸ”„'
        }.get(record['status'], 'â“')
        
        # ì†Œìš” ì‹œê°„ ê³„ì‚°
        duration = ""
        if record.get('completed_at'):
            start = datetime.fromisoformat(record['started_at'])
            end = datetime.fromisoformat(record['completed_at'])
            duration = _format_duration((end - start).total_seconds())
        elif record['status'] == 'in_progress':
            start = datetime.fromisoformat(record['started_at'])
            duration = _format_duration((datetime.now() - start).total_seconds()) + " (ì§„í–‰ì¤‘)"
        
        # ì‹œì‘ ì‹œê°„ í¬ë§·
        start_time = datetime.fromisoformat(record['started_at'])
        formatted_time = start_time.strftime("%m/%d %H:%M")
        
        table.add_row(
            record['run_id'][:8],
            record.get('profile', 'default'),
            f"{status_icon} {record['status']}",
            formatted_time,
            duration
        )
    
    console.print(table)

def _show_detailed_history(history: List[Dict[str, Any]]):
    """ìƒì„¸í•œ íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
    for i, record in enumerate(history):
        if i > 0:
            console.print()
        
        # ìƒíƒœë³„ ìƒ‰ìƒ
        status_color = {
            'completed': 'green',
            'failed': 'red',
            'in_progress': 'yellow'
        }.get(record['status'], 'white')
        
        # ê¸°ë³¸ ì •ë³´
        panel_content = f"[bold]Run ID:[/bold] {record['run_id']}\n"
        panel_content += f"[bold]í”„ë¡œíŒŒì¼:[/bold] {record.get('profile', 'default')}\n"
        panel_content += f"[bold]ìƒíƒœ:[/bold] [{status_color}]{record['status']}[/{status_color}]\n"
        panel_content += f"[bold]ì‹œì‘ ì‹œê°„:[/bold] {_format_datetime(record['started_at'])}\n"
        
        if record.get('completed_at'):
            panel_content += f"[bold]ì™„ë£Œ ì‹œê°„:[/bold] {_format_datetime(record['completed_at'])}\n"
            start = datetime.fromisoformat(record['started_at'])
            end = datetime.fromisoformat(record['completed_at'])
            duration = _format_duration((end - start).total_seconds())
            panel_content += f"[bold]ì†Œìš” ì‹œê°„:[/bold] {duration}\n"
        
        # ë‹¨ê³„ë³„ ì •ë³´ ë¡œë“œ
        step_info = _load_step_details(record['file'])
        if step_info:
            panel_content += "\n[bold]ë‹¨ê³„ë³„ ìƒíƒœ:[/bold]\n"
            for step_name, step_data in step_info.items():
                step_status = step_data.get('status', 'pending')
                step_icon = {
                    'completed': 'âœ…',
                    'failed': 'âŒ',
                    'in_progress': 'ğŸ”„',
                    'pending': 'â³',
                    'skipped': 'â­ï¸'
                }.get(step_status, 'â“')
                
                panel_content += f"  {step_icon} {step_name}"
                
                if step_data.get('duration'):
                    duration = _format_duration(step_data['duration'])
                    panel_content += f" ({duration})"
                
                if step_data.get('error'):
                    panel_content += f"\n    [red]ì˜¤ë¥˜: {step_data['error']}[/red]"
                
                panel_content += "\n"
        
        console.print(Panel(
            panel_content.rstrip(),
            title=f"ğŸ” ì‹¤í–‰ ê¸°ë¡ #{i+1}",
            expand=False
        ))

def _show_statistics(tracker: ExecutionTracker):
    """í†µê³„ ì •ë³´ í‘œì‹œ"""
    history = tracker.load_execution_history(100)  # ìµœê·¼ 100ê°œ ê¸°ë¡
    
    if not history:
        console.print("ğŸ“Š í†µê³„ë¥¼ ê³„ì‚°í•  íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ í†µê³„
    total_runs = len(history)
    successful_runs = len([h for h in history if h['status'] == 'completed'])
    failed_runs = len([h for h in history if h['status'] == 'failed'])
    success_rate = (successful_runs / total_runs * 100) if total_runs > 0 else 0
    
    # í”„ë¡œíŒŒì¼ë³„ í†µê³„
    profile_stats = {}
    for record in history:
        profile = record.get('profile', 'default')
        if profile not in profile_stats:
            profile_stats[profile] = {'total': 0, 'success': 0, 'failed': 0}
        
        profile_stats[profile]['total'] += 1
        if record['status'] == 'completed':
            profile_stats[profile]['success'] += 1
        elif record['status'] == 'failed':
            profile_stats[profile]['failed'] += 1
    
    # ì‹œê°„ëŒ€ë³„ ë¶„ì„
    time_analysis = _analyze_execution_times(history)
    
    # í†µê³„ í‘œì‹œ
    console.print("ğŸ“Š ì‹¤í–‰ í†µê³„ (ìµœê·¼ 100íšŒ)")
    console.print()
    
    # ì „ì²´ í†µê³„
    stats_table = Table(title="ì „ì²´ ì‹¤í–‰ í†µê³„")
    stats_table.add_column("í•­ëª©", style="bold")
    stats_table.add_column("ê°’", justify="right")
    
    stats_table.add_row("ì´ ì‹¤í–‰ íšŸìˆ˜", str(total_runs))
    stats_table.add_row("ì„±ê³µ", f"[green]{successful_runs}[/green]")
    stats_table.add_row("ì‹¤íŒ¨", f"[red]{failed_runs}[/red]")
    stats_table.add_row("ì„±ê³µë¥ ", f"[bold]{success_rate:.1f}%[/bold]")
    
    console.print(stats_table)
    console.print()
    
    # í”„ë¡œíŒŒì¼ë³„ í†µê³„
    if len(profile_stats) > 1:
        profile_table = Table(title="í”„ë¡œíŒŒì¼ë³„ í†µê³„")
        profile_table.add_column("í”„ë¡œíŒŒì¼", style="cyan")
        profile_table.add_column("ì´ ì‹¤í–‰", justify="center")
        profile_table.add_column("ì„±ê³µ", justify="center")
        profile_table.add_column("ì‹¤íŒ¨", justify="center")
        profile_table.add_column("ì„±ê³µë¥ ", justify="right")
        
        for profile, stats in profile_stats.items():
            rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
            profile_table.add_row(
                profile,
                str(stats['total']),
                f"[green]{stats['success']}[/green]",
                f"[red]{stats['failed']}[/red]",
                f"{rate:.1f}%"
            )
        
        console.print(profile_table)
        console.print()
    
    # ì‹œê°„ ë¶„ì„
    if time_analysis:
        console.print("â±ï¸  ì‹¤í–‰ ì‹œê°„ ë¶„ì„")
        console.print(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {time_analysis['avg_duration']}")
        console.print(f"ìµœë‹¨ ì‹¤í–‰ ì‹œê°„: {time_analysis['min_duration']}")
        console.print(f"ìµœì¥ ì‹¤í–‰ ì‹œê°„: {time_analysis['max_duration']}")

def _analyze_execution_times(history: List[Dict[str, Any]]) -> Dict[str, str]:
    """ì‹¤í–‰ ì‹œê°„ ë¶„ì„"""
    durations = []
    
    for record in history:
        if record.get('completed_at') and record['status'] == 'completed':
            start = datetime.fromisoformat(record['started_at'])
            end = datetime.fromisoformat(record['completed_at'])
            duration = (end - start).total_seconds()
            durations.append(duration)
    
    if not durations:
        return {}
    
    return {
        'avg_duration': _format_duration(sum(durations) / len(durations)),
        'min_duration': _format_duration(min(durations)),
        'max_duration': _format_duration(max(durations))
    }

def _clean_old_history(tracker: ExecutionTracker):
    """ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ ì •ë¦¬"""
    console.print("ğŸ§¹ ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ë¥¼ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    
    # 30ì¼ ì´ìƒ ëœ ê¸°ë¡ ì •ë¦¬
    tracker.cleanup_old_states(keep_days=30)
    
    console.print("âœ… íˆìŠ¤í† ë¦¬ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def _load_step_details(file_path: str) -> Dict[str, Any]:
    """ìƒíƒœ íŒŒì¼ì—ì„œ ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ë¡œë“œ"""
    try:
        import json
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('steps', {})
    except Exception:
        return {}

def _format_datetime(iso_string: str) -> str:
    """ë‚ ì§œì‹œê°„ í¬ë§·íŒ…"""
    dt = datetime.fromisoformat(iso_string)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def _format_duration(seconds: float) -> str:
    """ì†Œìš” ì‹œê°„ í¬ë§·íŒ…"""
    if seconds < 60:
        return f"{seconds:.1f}ì´ˆ"
    elif seconds < 3600:
        return f"{seconds/60:.1f}ë¶„"
    else:
        return f"{seconds/3600:.1f}ì‹œê°„"
```

### 2. ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ê¸° êµ¬í˜„
```python
# sbkube/utils/pattern_analyzer.py
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import statistics

class ExecutionPatternAnalyzer:
    """ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ê¸°"""
    
    def __init__(self, history: List[Dict[str, Any]]):
        self.history = history
    
    def analyze_failure_patterns(self) -> Dict[str, Any]:
        """ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„"""
        failed_executions = [h for h in self.history if h['status'] == 'failed']
        
        if not failed_executions:
            return {'failures': 0, 'patterns': []}
        
        # ì‹¤íŒ¨ ë‹¨ê³„ ë¶„ì„
        failure_steps = defaultdict(int)
        failure_errors = defaultdict(int)
        
        for execution in failed_executions:
            step_details = self._load_execution_details(execution)
            for step_name, step_data in step_details.get('steps', {}).items():
                if step_data.get('status') == 'failed':
                    failure_steps[step_name] += 1
                    if step_data.get('error'):
                        failure_errors[step_data['error']] += 1
        
        # ì‹œê°„ëŒ€ë³„ ì‹¤íŒ¨ ë¶„ì„
        failure_times = []
        for execution in failed_executions:
            dt = datetime.fromisoformat(execution['started_at'])
            failure_times.append(dt.hour)
        
        patterns = []
        
        # ê°€ì¥ ìì£¼ ì‹¤íŒ¨í•˜ëŠ” ë‹¨ê³„
        if failure_steps:
            most_failed_step = max(failure_steps.items(), key=lambda x: x[1])
            patterns.append({
                'type': 'frequent_failure_step',
                'description': f"'{most_failed_step[0]}' ë‹¨ê³„ì—ì„œ ê°€ì¥ ìì£¼ ì‹¤íŒ¨ ({most_failed_step[1]}íšŒ)",
                'recommendation': f"{most_failed_step[0]} ë‹¨ê³„ì˜ ì„¤ì •ì„ ì ê²€í•´ë³´ì„¸ìš”"
            })
        
        # ê°€ì¥ í”í•œ ì˜¤ë¥˜
        if failure_errors:
            most_common_error = max(failure_errors.items(), key=lambda x: x[1])
            patterns.append({
                'type': 'common_error',
                'description': f"ê°€ì¥ í”í•œ ì˜¤ë¥˜: {most_common_error[0]} ({most_common_error[1]}íšŒ)",
                'recommendation': "ì´ ì˜¤ë¥˜ì— ëŒ€í•œ í•´ê²° ë°©ë²•ì„ í™•ì¸í•´ë³´ì„¸ìš”"
            })
        
        # ì‹œê°„ëŒ€ë³„ ì‹¤íŒ¨ íŒ¨í„´
        if failure_times:
            failure_hour_counts = Counter(failure_times)
            if len(failure_hour_counts) > 1:
                peak_hour = max(failure_hour_counts.items(), key=lambda x: x[1])
                patterns.append({
                    'type': 'time_pattern',
                    'description': f"{peak_hour[0]}ì‹œê²½ì— ì‹¤íŒ¨ê°€ ìì£¼ ë°œìƒ ({peak_hour[1]}íšŒ)",
                    'recommendation': "í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ì‹œìŠ¤í…œ ë¶€í•˜ë‚˜ ë„¤íŠ¸ì›Œí¬ ìƒí™©ì„ í™•ì¸í•´ë³´ì„¸ìš”"
                })
        
        return {
            'total_failures': len(failed_executions),
            'failure_rate': len(failed_executions) / len(self.history) * 100,
            'patterns': patterns,
            'failure_steps': dict(failure_steps),
            'failure_errors': dict(failure_errors)
        }
    
    def analyze_performance_trends(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        completed_executions = []
        
        for execution in self.history:
            if execution['status'] == 'completed' and execution.get('completed_at'):
                start = datetime.fromisoformat(execution['started_at'])
                end = datetime.fromisoformat(execution['completed_at'])
                duration = (end - start).total_seconds()
                
                completed_executions.append({
                    'duration': duration,
                    'date': start.date(),
                    'profile': execution.get('profile', 'default')
                })
        
        if len(completed_executions) < 2:
            return {'trend': 'insufficient_data'}
        
        # ì‹œê°„ë³„ íŠ¸ë Œë“œ
        durations = [e['duration'] for e in completed_executions]
        recent_durations = durations[-5:]  # ìµœê·¼ 5íšŒ
        earlier_durations = durations[:-5] if len(durations) > 5 else durations
        
        trend_analysis = {}
        
        if len(recent_durations) >= 2 and len(earlier_durations) >= 2:
            recent_avg = statistics.mean(recent_durations)
            earlier_avg = statistics.mean(earlier_durations)
            
            if recent_avg > earlier_avg * 1.2:
                trend_analysis['performance'] = 'degrading'
                trend_analysis['change'] = f"{((recent_avg - earlier_avg) / earlier_avg * 100):.1f}% ëŠë ¤ì§"
            elif recent_avg < earlier_avg * 0.8:
                trend_analysis['performance'] = 'improving'
                trend_analysis['change'] = f"{((earlier_avg - recent_avg) / earlier_avg * 100):.1f}% ë¹¨ë¼ì§"
            else:
                trend_analysis['performance'] = 'stable'
                trend_analysis['change'] = "ì•ˆì •ì "
        
        # í”„ë¡œíŒŒì¼ë³„ ì„±ëŠ¥
        profile_performance = defaultdict(list)
        for execution in completed_executions:
            profile_performance[execution['profile']].append(execution['duration'])
        
        profile_stats = {}
        for profile, durations in profile_performance.items():
            if len(durations) >= 2:
                profile_stats[profile] = {
                    'avg_duration': statistics.mean(durations),
                    'min_duration': min(durations),
                    'max_duration': max(durations),
                    'std_dev': statistics.stdev(durations) if len(durations) > 1 else 0
                }
        
        return {
            'trend': trend_analysis,
            'profile_performance': profile_stats,
            'total_completed': len(completed_executions)
        }
    
    def generate_recommendations(self) -> List[Dict[str, str]]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        failure_analysis = self.analyze_failure_patterns()
        performance_analysis = self.analyze_performance_trends()
        
        # ì‹¤íŒ¨ìœ¨ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if failure_analysis['failure_rate'] > 20:
            recommendations.append({
                'priority': 'high',
                'category': 'reliability',
                'title': 'ë†’ì€ ì‹¤íŒ¨ìœ¨ ê°œì„ ',
                'description': f"ì‹¤íŒ¨ìœ¨ì´ {failure_analysis['failure_rate']:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì„¤ì •ê³¼ í™˜ê²½ì„ ì ê²€í•´ë³´ì„¸ìš”.",
                'action': "sbkube validateë¡œ ì„¤ì •ì„ ê²€ì¦í•˜ê³ , ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
            })
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        perf_trend = performance_analysis.get('trend', {})
        if perf_trend.get('performance') == 'degrading':
            recommendations.append({
                'priority': 'medium',
                'category': 'performance',
                'title': 'ì„±ëŠ¥ ì €í•˜ ê°ì§€',
                'description': f"ìµœê·¼ ì‹¤í–‰ ì‹œê°„ì´ {perf_trend['change']} ì¦ê°€í–ˆìŠµë‹ˆë‹¤.",
                'action': "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì™€ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
            })
        
        # íŒ¨í„´ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        for pattern in failure_analysis.get('patterns', []):
            if pattern['type'] == 'frequent_failure_step':
                recommendations.append({
                    'priority': 'high',
                    'category': 'configuration',
                    'title': f"ë°˜ë³µì ì¸ {pattern['description'].split("'")[1]} ë‹¨ê³„ ì‹¤íŒ¨",
                    'description': pattern['description'],
                    'action': pattern['recommendation']
                })
        
        return recommendations
    
    def _load_execution_details(self, execution: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤í–‰ ìƒì„¸ ì •ë³´ ë¡œë“œ"""
        try:
            import json
            with open(execution['file'], 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}
```

### 3. ì§„ë‹¨ ëª…ë ¹ì–´ ì¶”ê°€
```python
# sbkube/commands/history.pyì— ì¶”ê°€
@click.command(name="diagnose")
@click.option("--recommendations", is_flag=True, help="ê°œì„  ê¶Œì¥ì‚¬í•­ í‘œì‹œ")
@click.pass_context
def diagnose_cmd(ctx, recommendations):
    """ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ ë° ì§„ë‹¨
    
    ìµœê·¼ ì‹¤í–‰ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì œ íŒ¨í„´ì„ ì°¾ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.
    """
    try:
        tracker = ExecutionTracker(".")
        history = tracker.load_execution_history(50)
        
        if not history:
            console.print("ğŸ“‹ ë¶„ì„í•  íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        from sbkube.utils.pattern_analyzer import ExecutionPatternAnalyzer
        analyzer = ExecutionPatternAnalyzer(history)
        
        # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
        failure_analysis = analyzer.analyze_failure_patterns()
        console.print("ğŸ” ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„")
        console.print(f"ì´ ì‹¤íŒ¨ íšŸìˆ˜: {failure_analysis['total_failures']}")
        console.print(f"ì‹¤íŒ¨ìœ¨: {failure_analysis['failure_rate']:.1f}%")
        
        if failure_analysis['patterns']:
            console.print("\në°œê²¬ëœ íŒ¨í„´:")
            for pattern in failure_analysis['patterns']:
                console.print(f"  â€¢ {pattern['description']}")
        
        # ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
        performance_analysis = analyzer.analyze_performance_trends()
        perf_trend = performance_analysis.get('trend', {})
        
        if perf_trend:
            console.print(f"\nâš¡ ì„±ëŠ¥ íŠ¸ë Œë“œ")
            console.print(f"ìƒíƒœ: {perf_trend.get('performance', 'unknown')}")
            if 'change' in perf_trend:
                console.print(f"ë³€í™”: {perf_trend['change']}")
        
        # ê¶Œì¥ì‚¬í•­
        if recommendations:
            recs = analyzer.generate_recommendations()
            if recs:
                console.print("\nğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­")
                for rec in recs:
                    priority_color = {'high': 'red', 'medium': 'yellow', 'low': 'green'}.get(rec['priority'], 'white')
                    console.print(f"[{priority_color}]â€¢ {rec['title']}[/{priority_color}]")
                    console.print(f"  {rec['description']}")
                    console.print(f"  ê¶Œì¥ ì¡°ì¹˜: {rec['action']}")
                    console.print()
        
    except Exception as e:
        logger.error(f"âŒ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
        sys.exit(1)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ êµ¬í˜„

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/unit/commands/test_history.py
import pytest
import tempfile
import json
from pathlib import Path
from datetime import datetime, timedelta
from sbkube.utils.execution_tracker import ExecutionTracker
from sbkube.utils.pattern_analyzer import ExecutionPatternAnalyzer

class TestHistoryManagement:
    def test_history_loading(self):
        """íˆìŠ¤í† ë¦¬ ë¡œë”© í…ŒìŠ¤íŠ¸"""
        with tempfile.TemporaryDirectory() as tmpdir:
            tracker = ExecutionTracker(tmpdir)
            
            # í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ ìƒì„±
            self._create_test_history(tmpdir)
            
            history = tracker.load_execution_history(10)
            assert len(history) > 0
            assert 'run_id' in history[0]
            assert 'status' in history[0]
    
    def test_pattern_analysis(self):
        """íŒ¨í„´ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ ë°ì´í„°
        history = [
            {'status': 'failed', 'started_at': '2024-01-01T10:00:00', 'file': 'test1.json'},
            {'status': 'completed', 'started_at': '2024-01-01T11:00:00', 'completed_at': '2024-01-01T11:05:00'},
            {'status': 'failed', 'started_at': '2024-01-01T12:00:00', 'file': 'test2.json'},
        ]
        
        analyzer = ExecutionPatternAnalyzer(history)
        failure_analysis = analyzer.analyze_failure_patterns()
        
        assert failure_analysis['total_failures'] == 2
        assert failure_analysis['failure_rate'] > 0
    
    def _create_test_history(self, tmpdir):
        """í…ŒìŠ¤íŠ¸ìš© íˆìŠ¤í† ë¦¬ ìƒì„±"""
        runs_dir = Path(tmpdir) / ".sbkube" / "runs"
        runs_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„±ê³µ ì‹¤í–‰
        success_data = {
            'run_id': 'test-success-1',
            'status': 'completed',
            'started_at': datetime.now().isoformat(),
            'completed_at': (datetime.now() + timedelta(minutes=5)).isoformat(),
            'steps': {
                'prepare': {'status': 'completed'},
                'build': {'status': 'completed'},
                'template': {'status': 'completed'},
                'deploy': {'status': 'completed'}
            }
        }
        
        with open(runs_dir / "test-success-1.json", 'w') as f:
            json.dump(success_data, f)
        
        # ì‹¤íŒ¨ ì‹¤í–‰
        failure_data = {
            'run_id': 'test-failure-1',
            'status': 'failed',
            'started_at': datetime.now().isoformat(),
            'steps': {
                'prepare': {'status': 'completed'},
                'build': {'status': 'failed', 'error': 'Build failed'}
            }
        }
        
        with open(runs_dir / "test-failure-1.json", 'w') as f:
            json.dump(failure_data, f)
```

## âœ… ì™„ë£Œ ê¸°ì¤€

- [ ] history ëª…ë ¹ì–´ êµ¬í˜„ (list, detailed, failures, stats)
- [ ] ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ê¸° êµ¬í˜„
- [ ] í†µê³„ ì •ë³´ í‘œì‹œ ê¸°ëŠ¥
- [ ] ì§„ë‹¨ ëª…ë ¹ì–´ êµ¬í˜„
- [ ] ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ ì •ë¦¬ ê¸°ëŠ¥
- [ ] ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹œìŠ¤í…œ
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼

## ğŸ” ê²€ì¦ ëª…ë ¹ì–´

```bash
# íˆìŠ¤í† ë¦¬ ì¡°íšŒ
sbkube history
sbkube history --detailed
sbkube history --failures
sbkube history --stats

# íŒ¨í„´ ë¶„ì„
sbkube diagnose
sbkube diagnose --recommendations

# íˆìŠ¤í† ë¦¬ ì •ë¦¬
sbkube history --clean

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/unit/commands/test_history.py -v
```

## ğŸ“ ì˜ˆìƒ ê²°ê³¼

```bash
$ sbkube history --stats
ğŸ“Š ì‹¤í–‰ í†µê³„ (ìµœê·¼ 100íšŒ)

ì „ì²´ ì‹¤í–‰ í†µê³„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ í•­ëª©     â”‚  ê°’ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ ì´ ì‹¤í–‰ íšŸìˆ˜ â”‚  25 â”‚
â”‚ ì„±ê³µ     â”‚  20 â”‚
â”‚ ì‹¤íŒ¨     â”‚   5 â”‚
â”‚ ì„±ê³µë¥    â”‚80.0%â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

â±ï¸  ì‹¤í–‰ ì‹œê°„ ë¶„ì„
í‰ê·  ì‹¤í–‰ ì‹œê°„: 3.2ë¶„
ìµœë‹¨ ì‹¤í–‰ ì‹œê°„: 1.8ë¶„
ìµœì¥ ì‹¤í–‰ ì‹œê°„: 7.5ë¶„

$ sbkube diagnose --recommendations
ğŸ” ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
ì´ ì‹¤íŒ¨ íšŸìˆ˜: 5
ì‹¤íŒ¨ìœ¨: 20.0%

ë°œê²¬ëœ íŒ¨í„´:
  â€¢ 'build' ë‹¨ê³„ì—ì„œ ê°€ì¥ ìì£¼ ì‹¤íŒ¨ (3íšŒ)
  â€¢ ê°€ì¥ í”í•œ ì˜¤ë¥˜: Helm chart not found (2íšŒ)

âš¡ ì„±ëŠ¥ íŠ¸ë Œë“œ
ìƒíƒœ: stable
ë³€í™”: ì•ˆì •ì 

ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­
â€¢ ë°˜ë³µì ì¸ build ë‹¨ê³„ ì‹¤íŒ¨
  build ë‹¨ê³„ì—ì„œ ê°€ì¥ ìì£¼ ì‹¤íŒ¨ (3íšŒ)
  ê¶Œì¥ ì¡°ì¹˜: build ë‹¨ê³„ì˜ ì„¤ì •ì„ ì ê²€í•´ë³´ì„¸ìš”
```

## ğŸ”„ ë‹¤ìŒ ë‹¨ê³„

ì´ ì‘ì—… ì™„ë£Œ í›„ ë‹¤ìŒ ì‘ì—…ìœ¼ë¡œ ì§„í–‰:
- `010-progress-manager-implementation.md` - ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ ì‹œìŠ¤í…œ êµ¬í˜„