# Redis configuration for AI workloads
# High-performance caching for AI inference

architecture: standalone

auth:
  enabled: false

master:
  persistence:
    enabled: false
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
