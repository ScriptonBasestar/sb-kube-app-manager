name: End-to-End Tests

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:     # Manual trigger
  pull_request:
    paths:
      - 'sbkube/**'
      - 'tests/e2e/**'
      - '.github/workflows/e2e.yml'

jobs:
  e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    strategy:
      fail-fast: false
      matrix:
        scenario: ["ai-workflow", "data-pipeline", "monitoring-stack"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH
    
    - name: Install dependencies
      run: |
        uv venv
        uv pip install -e ".[test]"
    
    - name: Install Helm
      uses: azure/setup-helm@v3
      with:
        version: 'latest'
    
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
    
    - name: Setup Kind cluster
      uses: helm/kind-action@v1
      with:
        cluster_name: sbkube-e2e-${{ matrix.scenario }}
        config: |
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
          - role: control-plane
            kubeadmConfigPatches:
            - |
              kind: InitConfiguration
              nodeRegistration:
                kubeletExtraArgs:
                  node-labels: "ingress-ready=true"
            extraPortMappings:
            - containerPort: 80
              hostPort: 80
            - containerPort: 443
              hostPort: 443
    
    - name: Wait for cluster ready
      run: |
        kubectl wait --for=condition=Ready nodes --all --timeout=300s
        kubectl cluster-info
    
    - name: Run E2E tests for ${{ matrix.scenario }}
      run: |
        source .venv/bin/activate
        pytest -v tests/e2e/ -k "${{ matrix.scenario }}" --timeout=1800 --maxfail=1
      env:
        KUBECONFIG: /home/runner/.kube/config
    
    - name: Collect logs on failure
      if: failure()
      run: |
        echo "=== Cluster Info ==="
        kubectl cluster-info dump
        
        echo "=== All Pods ==="
        kubectl get pods --all-namespaces -o wide
        
        echo "=== Events ==="
        kubectl get events --all-namespaces --sort-by=.metadata.creationTimestamp
        
        echo "=== Helm Releases ==="
        helm list --all-namespaces
    
    - name: Upload logs
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: e2e-logs-${{ matrix.scenario }}
        path: |
          /tmp/sbkube-e2e-logs/
          cluster-dump.yaml
    
    - name: Cleanup
      if: always()
      run: |
        # Clean up test namespaces
        kubectl get namespaces | grep test- | awk '{print $1}' | xargs -r kubectl delete namespace --ignore-not-found=true || true
        
        # Delete kind cluster
        kind delete cluster --name sbkube-e2e-${{ matrix.scenario }} || true

  e2e-summary:
    runs-on: ubuntu-latest
    needs: e2e
    if: always()
    
    steps:
    - name: Check E2E results
      run: |
        if [[ "${{ needs.e2e.result }}" == "success" ]]; then
          echo "✅ All E2E tests passed"
        else
          echo "❌ Some E2E tests failed"
          exit 1
        fi
    
    - name: Create summary
      if: always()
      run: |
        echo "## E2E Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Scenario | Result |" >> $GITHUB_STEP_SUMMARY
        echo "|----------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| AI Workflow | ${{ needs.e2e.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Data Pipeline | ${{ needs.e2e.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Monitoring Stack | ${{ needs.e2e.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY