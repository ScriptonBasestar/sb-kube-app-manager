---
phase: 3
order: 13
source_plan: /tasks/plan/phase3-intelligent-features.md
priority: medium
tags: [workflow-engine, yaml-parser, parallel-execution]
estimated_days: 3
depends_on: [012-auto-fix-system]
---

# ğŸ“Œ ì‘ì—…: ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ì—”ì§„ êµ¬í˜„

## ğŸ¯ ëª©í‘œ
YAML ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì •ì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì—”ì§„ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì¡°ê±´ë¶€ ì‹¤í–‰, ë³‘ë ¬ ì²˜ë¦¬, ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ì„ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ“‹ ì‘ì—… ë‚´ìš©

### 1. ì›Œí¬í”Œë¡œìš° ëª¨ë¸ ì •ì˜
```python
# sbkube/models/workflow_model.py
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, field
from enum import Enum
import yaml

class StepType(Enum):
    BUILTIN = "builtin"        # sbkube ë‚´ì¥ ëª…ë ¹ì–´
    SCRIPT = "script"          # ì‚¬ìš©ì ìŠ¤í¬ë¦½íŠ¸
    PARALLEL = "parallel"      # ë³‘ë ¬ ì‹¤í–‰ ê·¸ë£¹

class StepStatus(Enum):
    PENDING = "pending"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class WorkflowStep:
    """ì›Œí¬í”Œë¡œìš° ë‹¨ê³„"""
    name: str
    type: StepType = StepType.BUILTIN
    command: Optional[str] = None
    script: Optional[str] = None
    condition: Optional[str] = None
    parallel: bool = False
    apps: Optional[List[str]] = None
    timeout: int = 300  # 5ë¶„ ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ
    retry_count: int = 0
    on_failure: Optional[str] = None  # continue, stop, retry
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # ì‹¤í–‰ ìƒíƒœ
    status: StepStatus = StepStatus.PENDING
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    output: Optional[str] = None
    error: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'name': self.name,
            'type': self.type.value,
            'command': self.command,
            'script': self.script,
            'condition': self.condition,
            'parallel': self.parallel,
            'apps': self.apps,
            'timeout': self.timeout,
            'retry_count': self.retry_count,
            'on_failure': self.on_failure,
            'metadata': self.metadata,
            'status': self.status.value,
            'started_at': self.started_at,
            'completed_at': self.completed_at,
            'output': self.output,
            'error': self.error
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'WorkflowStep':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒì„±"""
        step = cls(
            name=data['name'],
            type=StepType(data.get('type', 'builtin')),
            command=data.get('command'),
            script=data.get('script'),
            condition=data.get('condition'),
            parallel=data.get('parallel', False),
            apps=data.get('apps'),
            timeout=data.get('timeout', 300),
            retry_count=data.get('retry_count', 0),
            on_failure=data.get('on_failure'),
            metadata=data.get('metadata', {})
        )
        
        # ì‹¤í–‰ ìƒíƒœ ë³µì›
        if 'status' in data:
            step.status = StepStatus(data['status'])
        step.started_at = data.get('started_at')
        step.completed_at = data.get('completed_at')
        step.output = data.get('output')
        step.error = data.get('error')
        
        return step

@dataclass
class Workflow:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜"""
    name: str
    description: str = ""
    version: str = "1.0"
    variables: Dict[str, Any] = field(default_factory=dict)
    steps: List[WorkflowStep] = field(default_factory=list)
    
    # ì‹¤í–‰ ìƒíƒœ
    status: StepStatus = StepStatus.PENDING
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'name': self.name,
            'description': self.description,
            'version': self.version,
            'variables': self.variables,
            'steps': [step.to_dict() for step in self.steps],
            'status': self.status.value,
            'started_at': self.started_at,
            'completed_at': self.completed_at
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Workflow':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒì„±"""
        workflow = cls(
            name=data['name'],
            description=data.get('description', ''),
            version=data.get('version', '1.0'),
            variables=data.get('variables', {}),
            steps=[WorkflowStep.from_dict(step_data) for step_data in data.get('steps', [])]
        )
        
        # ì‹¤í–‰ ìƒíƒœ ë³µì›
        if 'status' in data:
            workflow.status = StepStatus(data['status'])
        workflow.started_at = data.get('started_at')
        workflow.completed_at = data.get('completed_at')
        
        return workflow
    
    @classmethod
    def from_yaml_file(cls, file_path: str) -> 'Workflow':
        """YAML íŒŒì¼ì—ì„œ ë¡œë“œ"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        return cls.from_dict(data)
    
    def save_to_yaml(self, file_path: str):
        """YAML íŒŒì¼ë¡œ ì €ì¥"""
        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(self.to_dict(), f, default_flow_style=False, allow_unicode=True)
    
    def get_step(self, name: str) -> Optional[WorkflowStep]:
        """ë‹¨ê³„ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ"""
        return next((step for step in self.steps if step.name == name), None)
    
    def get_pending_steps(self) -> List[WorkflowStep]:
        """ëŒ€ê¸° ì¤‘ì¸ ë‹¨ê³„ë“¤"""
        return [step for step in self.steps if step.status == StepStatus.PENDING]
    
    def get_failed_steps(self) -> List[WorkflowStep]:
        """ì‹¤íŒ¨í•œ ë‹¨ê³„ë“¤"""
        return [step for step in self.steps if step.status == StepStatus.FAILED]
```

### 2. ì¡°ê±´ í‰ê°€ ì‹œìŠ¤í…œ êµ¬í˜„
```python
# sbkube/utils/condition_evaluator.py
import re
import os
from typing import Dict, Any, Union

class ConditionEvaluator:
    """ì¡°ê±´ í‰ê°€ê¸°"""
    
    def __init__(self, context: Dict[str, Any] = None):
        self.context = context or {}
        self.context.update({
            'env': dict(os.environ),
            'true': True,
            'false': False,
            'null': None
        })
    
    def evaluate(self, condition: str) -> bool:
        """ì¡°ê±´ í‰ê°€"""
        if not condition or condition.strip() == "":
            return True
        
        try:
            # ì•ˆì „í•œ í‰ê°€ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬
            safe_condition = self._preprocess_condition(condition)
            
            # ì œí•œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ í‰ê°€
            allowed_names = {
                '__builtins__': {},
                **self.context
            }
            
            result = eval(safe_condition, allowed_names)
            return bool(result)
            
        except Exception as e:
            # ì¡°ê±´ í‰ê°€ ì‹¤íŒ¨ ì‹œ False ë°˜í™˜
            print(f"ì¡°ê±´ í‰ê°€ ì‹¤íŒ¨ '{condition}': {e}")
            return False
    
    def _preprocess_condition(self, condition: str) -> str:
        """ì¡°ê±´ ì „ì²˜ë¦¬"""
        # ë³€ìˆ˜ ì°¸ì¡° ì²˜ë¦¬ (${var} -> context['var'])
        condition = re.sub(
            r'\$\{([^}]+)\}',
            lambda m: f"context.get('{m.group(1)}', None)",
            condition
        )
        
        # í™˜ê²½ë³€ìˆ˜ ì°¸ì¡° ì²˜ë¦¬ ($VAR -> env.get('VAR'))
        condition = re.sub(
            r'\$([A-Z_][A-Z0-9_]*)',
            lambda m: f"env.get('{m.group(1)}', '')",
            condition
        )
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸ í•¨ìˆ˜
        condition = re.sub(
            r'file\.exists\([\'"]([^\'"]+)[\'"]\)',
            lambda m: f"__import__('pathlib').Path('{m.group(1)}').exists()",
            condition
        )
        
        # ìºì‹œ ì¡´ì¬ í™•ì¸ í•¨ìˆ˜
        condition = re.sub(
            r'cache\.exists\([\'"]([^\'"]+)[\'"]\)',
            lambda m: f"context.get('cache', {{}}).get('{m.group(1)}', False)",
            condition
        )
        
        return condition
    
    def update_context(self, updates: Dict[str, Any]):
        """ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        self.context.update(updates)

# ì¡°ê±´ í‰ê°€ í—¬í¼ í•¨ìˆ˜ë“¤
def check_environment(env_name: str) -> bool:
    """í™˜ê²½ í™•ì¸"""
    return os.environ.get('ENVIRONMENT') == env_name

def check_profile(profile_name: str, context: Dict[str, Any]) -> bool:
    """í”„ë¡œíŒŒì¼ í™•ì¸"""
    return context.get('profile') == profile_name

def check_app_exists(app_name: str, context: Dict[str, Any]) -> bool:
    """ì•± ì¡´ì¬ í™•ì¸"""
    apps = context.get('config', {}).get('apps', [])
    return any(app.get('name') == app_name for app in apps)
```

### 3. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„ êµ¬í˜„
```python
# sbkube/utils/workflow_engine.py
import asyncio
import subprocess
import time
from datetime import datetime
from typing import Dict, Any, List, Optional, Callable
from pathlib import Path
import concurrent.futures

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from rich.live import Live
from rich.panel import Panel

from sbkube.models.workflow_model import Workflow, WorkflowStep, StepType, StepStatus
from sbkube.utils.condition_evaluator import ConditionEvaluator
from sbkube.utils.logger import logger

class WorkflowEngine:
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„"""
    
    def __init__(self, console: Console = None, max_parallel: int = 4):
        self.console = console or Console()
        self.max_parallel = max_parallel
        self.evaluator = ConditionEvaluator()
        self.builtin_commands = {
            'prepare': self._execute_prepare,
            'build': self._execute_build,
            'template': self._execute_template,
            'deploy': self._execute_deploy,
            'validate': self._execute_validate
        }
        
        # ì‹¤í–‰ ìƒíƒœ
        self.current_workflow: Optional[Workflow] = None
        self.step_progress: Dict[str, Any] = {}
        
    async def execute_workflow(self, workflow: Workflow, context: Dict[str, Any] = None) -> bool:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        self.current_workflow = workflow
        self.evaluator.update_context(context or {})
        
        logger.info(f"ğŸš€ ì›Œí¬í”Œë¡œìš° '{workflow.name}' ì‹¤í–‰ ì‹œì‘")
        
        workflow.status = StepStatus.RUNNING
        workflow.started_at = datetime.now().isoformat()
        
        try:
            success = await self._execute_steps(workflow.steps)
            
            if success:
                workflow.status = StepStatus.COMPLETED
                logger.success("âœ… ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ")
            else:
                workflow.status = StepStatus.FAILED
                logger.error("âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            workflow.status = StepStatus.FAILED
            logger.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
        
        finally:
            workflow.completed_at = datetime.now().isoformat()
    
    async def _execute_steps(self, steps: List[WorkflowStep]) -> bool:
        """ë‹¨ê³„ë“¤ ì‹¤í–‰"""
        for step in steps:
            # ì¡°ê±´ í™•ì¸
            if step.condition and not self.evaluator.evaluate(step.condition):
                step.status = StepStatus.SKIPPED
                logger.info(f"â­ï¸  ë‹¨ê³„ ê±´ë„ˆë›°ê¸°: {step.name} (ì¡°ê±´ ë¶ˆë§Œì¡±)")
                continue
            
            # ë‹¨ê³„ ì‹¤í–‰
            if step.parallel and step.apps:
                success = await self._execute_parallel_step(step)
            else:
                success = await self._execute_single_step(step)
            
            if not success:
                # ì‹¤íŒ¨ ì²˜ë¦¬
                if step.on_failure == "continue":
                    logger.warning(f"âš ï¸  ë‹¨ê³„ ì‹¤íŒ¨í–ˆì§€ë§Œ ê³„ì† ì§„í–‰: {step.name}")
                    continue
                elif step.on_failure == "retry" and step.retry_count > 0:
                    logger.info(f"ğŸ”„ ë‹¨ê³„ ì¬ì‹œë„: {step.name}")
                    step.retry_count -= 1
                    success = await self._execute_single_step(step)
                    if not success:
                        return False
                else:
                    logger.error(f"âŒ ë‹¨ê³„ ì‹¤íŒ¨ë¡œ ì¤‘ë‹¨: {step.name}")
                    return False
        
        return True
    
    async def _execute_single_step(self, step: WorkflowStep) -> bool:
        """ë‹¨ì¼ ë‹¨ê³„ ì‹¤í–‰"""
        step.status = StepStatus.RUNNING
        step.started_at = datetime.now().isoformat()
        
        logger.info(f"ğŸ”„ ì‹¤í–‰ ì¤‘: {step.name}")
        
        try:
            if step.type == StepType.BUILTIN:
                success = await self._execute_builtin_step(step)
            elif step.type == StepType.SCRIPT:
                success = await self._execute_script_step(step)
            else:
                logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ê³„ íƒ€ì…: {step.type}")
                success = False
            
            if success:
                step.status = StepStatus.COMPLETED
                logger.success(f"âœ… ì™„ë£Œ: {step.name}")
            else:
                step.status = StepStatus.FAILED
                logger.error(f"âŒ ì‹¤íŒ¨: {step.name}")
            
            return success
            
        except Exception as e:
            step.status = StepStatus.FAILED
            step.error = str(e)
            logger.error(f"âŒ ë‹¨ê³„ ì‹¤í–‰ ì˜¤ë¥˜ ({step.name}): {e}")
            return False
        
        finally:
            step.completed_at = datetime.now().isoformat()
    
    async def _execute_parallel_step(self, step: WorkflowStep) -> bool:
        """ë³‘ë ¬ ë‹¨ê³„ ì‹¤í–‰"""
        if not step.apps:
            return await self._execute_single_step(step)
        
        step.status = StepStatus.RUNNING
        step.started_at = datetime.now().isoformat()
        
        logger.info(f"ğŸ”„ ë³‘ë ¬ ì‹¤í–‰: {step.name} ({len(step.apps)}ê°œ ì•±)")
        
        # ì•±ë³„ë¡œ ê°œë³„ ë‹¨ê³„ ìƒì„±
        parallel_steps = []
        for app in step.apps:
            app_step = WorkflowStep(
                name=f"{step.name}-{app}",
                type=step.type,
                command=step.command,
                script=step.script,
                timeout=step.timeout
            )
            # ì•± ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
            app_step.metadata = {'target_app': app}
            parallel_steps.append(app_step)
        
        # ë³‘ë ¬ ì‹¤í–‰
        tasks = []
        semaphore = asyncio.Semaphore(self.max_parallel)
        
        async def execute_with_semaphore(app_step):
            async with semaphore:
                return await self._execute_single_step(app_step)
        
        for app_step in parallel_steps:
            task = asyncio.create_task(execute_with_semaphore(app_step))
            tasks.append(task)
        
        # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì§‘ê³„
        success_count = sum(1 for result in results if result is True)
        total_count = len(results)
        
        if success_count == total_count:
            step.status = StepStatus.COMPLETED
            logger.success(f"âœ… ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: {step.name} ({success_count}/{total_count})")
            return True
        else:
            step.status = StepStatus.FAILED
            step.error = f"ë³‘ë ¬ ì‹¤í–‰ ì¼ë¶€ ì‹¤íŒ¨: {success_count}/{total_count}"
            logger.error(f"âŒ ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {step.name} ({success_count}/{total_count})")
            return False
    
    async def _execute_builtin_step(self, step: WorkflowStep) -> bool:
        """ë‚´ì¥ ëª…ë ¹ì–´ ì‹¤í–‰"""
        command = step.command or step.name
        
        if command in self.builtin_commands:
            return await self.builtin_commands[command](step)
        else:
            logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‚´ì¥ ëª…ë ¹ì–´: {command}")
            return False
    
    async def _execute_script_step(self, step: WorkflowStep) -> bool:
        """ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""
        if not step.script:
            logger.error("ìŠ¤í¬ë¦½íŠ¸ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        try:
            # ë¹„ë™ê¸° í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
            process = await asyncio.create_subprocess_shell(
                step.script,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì‹¤í–‰
            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=step.timeout
            )
            
            # ê²°ê³¼ ì €ì¥
            step.output = stdout.decode('utf-8') if stdout else ""
            if stderr:
                step.error = stderr.decode('utf-8')
            
            return process.returncode == 0
            
        except asyncio.TimeoutError:
            step.error = f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ ({step.timeout}ì´ˆ)"
            return False
        except Exception as e:
            step.error = str(e)
            return False
    
    # ë‚´ì¥ ëª…ë ¹ì–´ êµ¬í˜„ë“¤
    async def _execute_prepare(self, step: WorkflowStep) -> bool:
        """ì¤€ë¹„ ë‹¨ê³„ ì‹¤í–‰"""
        # ì‹¤ì œ ì¤€ë¹„ ë¡œì§ êµ¬í˜„
        await asyncio.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
        return True
    
    async def _execute_build(self, step: WorkflowStep) -> bool:
        """ë¹Œë“œ ë‹¨ê³„ ì‹¤í–‰"""
        # ì‹¤ì œ ë¹Œë“œ ë¡œì§ êµ¬í˜„
        target_app = step.metadata.get('target_app')
        if target_app:
            logger.info(f"  ğŸ“¦ ë¹Œë“œ ì¤‘: {target_app}")
        
        await asyncio.sleep(2)  # ì‹œë®¬ë ˆì´ì…˜
        return True
    
    async def _execute_template(self, step: WorkflowStep) -> bool:
        """í…œí”Œë¦¿ ë‹¨ê³„ ì‹¤í–‰"""
        # ì‹¤ì œ í…œí”Œë¦¿ ë¡œì§ êµ¬í˜„
        await asyncio.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
        return True
    
    async def _execute_deploy(self, step: WorkflowStep) -> bool:
        """ë°°í¬ ë‹¨ê³„ ì‹¤í–‰"""
        # ì‹¤ì œ ë°°í¬ ë¡œì§ êµ¬í˜„
        target_app = step.metadata.get('target_app')
        if target_app:
            logger.info(f"  ğŸš€ ë°°í¬ ì¤‘: {target_app}")
        
        await asyncio.sleep(3)  # ì‹œë®¬ë ˆì´ì…˜
        return True
    
    async def _execute_validate(self, step: WorkflowStep) -> bool:
        """ê²€ì¦ ë‹¨ê³„ ì‹¤í–‰"""
        # ì‹¤ì œ ê²€ì¦ ë¡œì§ êµ¬í˜„
        await asyncio.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
        return True
```

### 4. ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì êµ¬í˜„
```python
# sbkube/utils/workflow_manager.py
from typing import Dict, Any, List, Optional
from pathlib import Path
import yaml

from sbkube.models.workflow_model import Workflow
from sbkube.utils.logger import logger

class WorkflowManager:
    """ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì"""
    
    def __init__(self, workflows_dir: str = ".sbkube/workflows"):
        self.workflows_dir = Path(workflows_dir)
        self.workflows_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìƒì„±
        self._create_default_workflows()
    
    def list_workflows(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° ëª©ë¡"""
        workflows = []
        
        for workflow_file in self.workflows_dir.glob("*.yaml"):
            try:
                with open(workflow_file, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                
                workflows.append({
                    'name': data.get('name', workflow_file.stem),
                    'description': data.get('description', ''),
                    'version': data.get('version', '1.0'),
                    'steps_count': len(data.get('steps', [])),
                    'file': str(workflow_file)
                })
                
            except Exception as e:
                logger.warning(f"ì›Œí¬í”Œë¡œìš° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({workflow_file}): {e}")
        
        return workflows
    
    def load_workflow(self, name: str) -> Optional[Workflow]:
        """ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        workflow_file = self.workflows_dir / f"{name}.yaml"
        
        if not workflow_file.exists():
            # ë‚´ì¥ ì›Œí¬í”Œë¡œìš° í™•ì¸
            builtin_file = self._get_builtin_workflow_path(name)
            if builtin_file and builtin_file.exists():
                workflow_file = builtin_file
            else:
                return None
        
        try:
            return Workflow.from_yaml_file(str(workflow_file))
        except Exception as e:
            logger.error(f"ì›Œí¬í”Œë¡œìš° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def save_workflow(self, workflow: Workflow) -> bool:
        """ì›Œí¬í”Œë¡œìš° ì €ì¥"""
        try:
            workflow_file = self.workflows_dir / f"{workflow.name}.yaml"
            workflow.save_to_yaml(str(workflow_file))
            logger.info(f"ì›Œí¬í”Œë¡œìš° ì €ì¥ë¨: {workflow_file}")
            return True
        except Exception as e:
            logger.error(f"ì›Œí¬í”Œë¡œìš° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def delete_workflow(self, name: str) -> bool:
        """ì›Œí¬í”Œë¡œìš° ì‚­ì œ"""
        workflow_file = self.workflows_dir / f"{name}.yaml"
        
        if workflow_file.exists():
            try:
                workflow_file.unlink()
                logger.info(f"ì›Œí¬í”Œë¡œìš° ì‚­ì œë¨: {name}")
                return True
            except Exception as e:
                logger.error(f"ì›Œí¬í”Œë¡œìš° ì‚­ì œ ì‹¤íŒ¨: {e}")
                return False
        
        return False
    
    def _create_default_workflows(self):
        """ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        default_workflows = {
            'quick-deploy': {
                'name': 'quick-deploy',
                'description': 'ë¹ ë¥¸ ë°°í¬ (ìºì‹œ í™œìš©)',
                'version': '1.0',
                'variables': {
                    'use_cache': True
                },
                'steps': [
                    {
                        'name': 'prepare',
                        'type': 'builtin',
                        'condition': '!cache.exists("charts")'
                    },
                    {
                        'name': 'deploy',
                        'type': 'builtin',
                        'parallel': True,
                        'apps': ['frontend', 'backend']
                    }
                ]
            },
            'full-ci-cd': {
                'name': 'full-ci-cd',
                'description': 'ì „ì²´ CI/CD íŒŒì´í”„ë¼ì¸',
                'version': '1.0',
                'steps': [
                    {
                        'name': 'validate',
                        'type': 'builtin'
                    },
                    {
                        'name': 'test',
                        'type': 'script',
                        'script': 'pytest tests/',
                        'on_failure': 'stop'
                    },
                    {
                        'name': 'build',
                        'type': 'builtin'
                    },
                    {
                        'name': 'security-scan',
                        'type': 'script',
                        'script': 'bandit -r sbkube/',
                        'on_failure': 'continue'
                    },
                    {
                        'name': 'deploy',
                        'type': 'builtin',
                        'condition': 'env.get("ENVIRONMENT") == "production"'
                    },
                    {
                        'name': 'smoke-test',
                        'type': 'script',
                        'script': 'curl -f http://app.example.com/health',
                        'timeout': 60
                    }
                ]
            }
        }
        
        for workflow_name, workflow_data in default_workflows.items():
            workflow_file = self.workflows_dir / f"{workflow_name}.yaml"
            
            if not workflow_file.exists():
                try:
                    with open(workflow_file, 'w', encoding='utf-8') as f:
                        yaml.dump(workflow_data, f, default_flow_style=False, allow_unicode=True)
                except Exception as e:
                    logger.warning(f"ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨ ({workflow_name}): {e}")
    
    def _get_builtin_workflow_path(self, name: str) -> Optional[Path]:
        """ë‚´ì¥ ì›Œí¬í”Œë¡œìš° ê²½ë¡œ ë°˜í™˜"""
        # íŒ¨í‚¤ì§€ ë‚´ ì›Œí¬í”Œë¡œìš° ë””ë ‰í† ë¦¬
        import sbkube
        package_dir = Path(sbkube.__file__).parent
        builtin_path = package_dir / "workflows" / f"{name}.yaml"
        
        return builtin_path if builtin_path.exists() else None
```

### 5. ì›Œí¬í”Œë¡œìš° ëª…ë ¹ì–´ êµ¬í˜„
```python
# sbkube/commands/workflow.py
import click
import sys
import asyncio
from typing import Dict, Any

from rich.console import Console
from rich.table import Table
from rich.panel import Panel

from sbkube.utils.workflow_manager import WorkflowManager
from sbkube.utils.workflow_engine import WorkflowEngine
from sbkube.utils.logger import logger

console = Console()

@click.group(name="workflow")
def workflow_group():
    """ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬"""
    pass

@workflow_group.command("list")
@click.option("--detailed", is_flag=True, help="ìƒì„¸ ì •ë³´ í‘œì‹œ")
def list_workflows(detailed):
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° ëª©ë¡"""
    try:
        manager = WorkflowManager()
        workflows = manager.list_workflows()
        
        if not workflows:
            console.print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if detailed:
            _show_detailed_workflows(workflows)
        else:
            _show_simple_workflows(workflows)
            
    except Exception as e:
        logger.error(f"âŒ ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)

@workflow_group.command("run")
@click.argument("workflow_name")
@click.option("--var", multiple=True, help="ë³€ìˆ˜ ì„¤ì • (key=value)")
@click.option("--profile", help="ì‚¬ìš©í•  í”„ë¡œíŒŒì¼")
@click.option("--dry-run", is_flag=True, help="ì‹¤ì œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ê³„íšë§Œ í‘œì‹œ")
def run_workflow(workflow_name, var, profile, dry_run):
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    try:
        manager = WorkflowManager()
        workflow = manager.load_workflow(workflow_name)
        
        if not workflow:
            console.print(f"âŒ ì›Œí¬í”Œë¡œìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {workflow_name}")
            sys.exit(1)
        
        # ë³€ìˆ˜ íŒŒì‹±
        variables = {}
        for v in var:
            if '=' in v:
                key, value = v.split('=', 1)
                variables[key] = value
        
        # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = {
            'profile': profile,
            'variables': variables,
            'workflow_name': workflow_name
        }
        
        if dry_run:
            _show_workflow_plan(workflow, context)
            return
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        engine = WorkflowEngine(console)
        success = asyncio.run(engine.execute_workflow(workflow, context))
        
        sys.exit(0 if success else 1)
        
    except Exception as e:
        logger.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

@workflow_group.command("show")
@click.argument("workflow_name")
def show_workflow(workflow_name):
    """ì›Œí¬í”Œë¡œìš° ìƒì„¸ ì •ë³´ í‘œì‹œ"""
    try:
        manager = WorkflowManager()
        workflow = manager.load_workflow(workflow_name)
        
        if not workflow:
            console.print(f"âŒ ì›Œí¬í”Œë¡œìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {workflow_name}")
            sys.exit(1)
        
        _show_workflow_details(workflow)
        
    except Exception as e:
        logger.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)

def _show_simple_workflows(workflows: List[Dict[str, Any]]):
    """ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš° ëª©ë¡"""
    table = Table(title="ğŸ”„ ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°")
    table.add_column("ì´ë¦„", style="cyan")
    table.add_column("ì„¤ëª…", style="green")
    table.add_column("ë‹¨ê³„ ìˆ˜", justify="center")
    table.add_column("ë²„ì „", justify="center")
    
    for workflow in workflows:
        table.add_row(
            workflow["name"],
            workflow["description"],
            str(workflow["steps_count"]),
            workflow["version"]
        )
    
    console.print(table)

def _show_detailed_workflows(workflows: List[Dict[str, Any]]):
    """ìƒì„¸í•œ ì›Œí¬í”Œë¡œìš° ëª©ë¡"""
    for workflow in workflows:
        panel_content = f"""[bold]ì„¤ëª…:[/bold] {workflow['description']}
[bold]ë²„ì „:[/bold] {workflow['version']}
[bold]ë‹¨ê³„ ìˆ˜:[/bold] {workflow['steps_count']}
[bold]íŒŒì¼:[/bold] {workflow['file']}"""
        
        console.print(Panel(
            panel_content,
            title=f"ğŸ”„ {workflow['name']}",
            expand=False
        ))

def _show_workflow_plan(workflow, context: Dict[str, Any]):
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê³„íš í‘œì‹œ"""
    console.print(f"ğŸ” ì›Œí¬í”Œë¡œìš° '{workflow.name}' ì‹¤í–‰ ê³„íš:")
    console.print("â”" * 50)
    
    for i, step in enumerate(workflow.steps, 1):
        step_info = f"{i}. {step.name}"
        
        if step.type.value != "builtin":
            step_info += f" ({step.type.value})"
        
        if step.condition:
            step_info += f" [ì¡°ê±´: {step.condition}]"
        
        if step.parallel and step.apps:
            step_info += f" [ë³‘ë ¬: {', '.join(step.apps)}]"
        
        console.print(step_info)
        
        if step.script:
            console.print(f"   ìŠ¤í¬ë¦½íŠ¸: {step.script}")
        elif step.command:
            console.print(f"   ëª…ë ¹ì–´: {step.command}")
    
    console.print(f"\nğŸ’¡ ì‹¤ì œ ì‹¤í–‰í•˜ë ¤ë©´ --dry-run ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”.")

def _show_workflow_details(workflow):
    """ì›Œí¬í”Œë¡œìš° ìƒì„¸ ì •ë³´"""
    console.print(f"ğŸ”„ ì›Œí¬í”Œë¡œìš°: {workflow.name}")
    console.print(f"ğŸ“ ì„¤ëª…: {workflow.description}")
    console.print(f"ğŸ·ï¸  ë²„ì „: {workflow.version}")
    
    if workflow.variables:
        console.print("\nğŸ“Š ë³€ìˆ˜:")
        for key, value in workflow.variables.items():
            console.print(f"  {key}: {value}")
    
    console.print("\nğŸ“‹ ë‹¨ê³„:")
    for i, step in enumerate(workflow.steps, 1):
        console.print(f"  {i}. {step.name}")
        if step.condition:
            console.print(f"     ì¡°ê±´: {step.condition}")
        if step.parallel and step.apps:
            console.print(f"     ë³‘ë ¬ ì‹¤í–‰: {', '.join(step.apps)}")
        if step.script:
            console.print(f"     ìŠ¤í¬ë¦½íŠ¸: {step.script}")
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ êµ¬í˜„

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/unit/utils/test_workflow_engine.py
import pytest
import asyncio
from unittest.mock import patch, MagicMock

from sbkube.models.workflow_model import Workflow, WorkflowStep, StepType, StepStatus
from sbkube.utils.workflow_engine import WorkflowEngine
from sbkube.utils.condition_evaluator import ConditionEvaluator

class TestWorkflowEngine:
    def test_workflow_model_creation(self):
        """ì›Œí¬í”Œë¡œìš° ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
        step = WorkflowStep(
            name="test-step",
            type=StepType.BUILTIN,
            command="prepare"
        )
        
        workflow = Workflow(
            name="test-workflow",
            description="í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš°",
            steps=[step]
        )
        
        assert workflow.name == "test-workflow"
        assert len(workflow.steps) == 1
        assert workflow.steps[0].name == "test-step"
    
    def test_condition_evaluator(self):
        """ì¡°ê±´ í‰ê°€ê¸° í…ŒìŠ¤íŠ¸"""
        evaluator = ConditionEvaluator({
            'env': 'production',
            'cache': {'charts': True}
        })
        
        # ê¸°ë³¸ ì¡°ê±´
        assert evaluator.evaluate("true") == True
        assert evaluator.evaluate("false") == False
        
        # ë³€ìˆ˜ ì°¸ì¡°
        assert evaluator.evaluate("context.get('env') == 'production'") == True
        
        # ìºì‹œ í™•ì¸
        assert evaluator.evaluate("cache.exists('charts')") == True
    
    @pytest.mark.asyncio
    async def test_workflow_execution(self):
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        step1 = WorkflowStep(name="step1", type=StepType.BUILTIN, command="prepare")
        step2 = WorkflowStep(name="step2", type=StepType.BUILTIN, command="build")
        
        workflow = Workflow(
            name="test-workflow",
            steps=[step1, step2]
        )
        
        engine = WorkflowEngine()
        
        # Mock ë‚´ì¥ ëª…ë ¹ì–´
        with patch.object(engine, '_execute_prepare', return_value=True), \
             patch.object(engine, '_execute_build', return_value=True):
            
            success = await engine.execute_workflow(workflow)
            
            assert success == True
            assert workflow.status == StepStatus.COMPLETED
            assert step1.status == StepStatus.COMPLETED
            assert step2.status == StepStatus.COMPLETED
    
    @pytest.mark.asyncio
    async def test_parallel_execution(self):
        """ë³‘ë ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        step = WorkflowStep(
            name="parallel-build",
            type=StepType.BUILTIN,
            command="build",
            parallel=True,
            apps=["app1", "app2", "app3"]
        )
        
        workflow = Workflow(name="test", steps=[step])
        engine = WorkflowEngine()
        
        with patch.object(engine, '_execute_build', return_value=True):
            success = await engine.execute_workflow(workflow)
            
            assert success == True
            assert step.status == StepStatus.COMPLETED
```

## âœ… ì™„ë£Œ ê¸°ì¤€

- [ ] ì›Œí¬í”Œë¡œìš° ëª¨ë¸ ì •ì˜ (Workflow, WorkflowStep)
- [ ] ì¡°ê±´ í‰ê°€ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„ êµ¬í˜„
- [ ] ë³‘ë ¬ ì‹¤í–‰ ë° íƒ€ì„ì•„ì›ƒ ì§€ì›
- [ ] ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì êµ¬í˜„
- [ ] ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì œê³µ
- [ ] ì›Œí¬í”Œë¡œìš° ëª…ë ¹ì–´ êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼

## ğŸ” ê²€ì¦ ëª…ë ¹ì–´

```bash
# ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ
sbkube workflow list
sbkube workflow list --detailed

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
sbkube workflow run quick-deploy
sbkube workflow run full-ci-cd --profile production

# ì‹¤í–‰ ê³„íš í™•ì¸
sbkube workflow run quick-deploy --dry-run

# ì›Œí¬í”Œë¡œìš° ìƒì„¸ ì •ë³´
sbkube workflow show full-ci-cd

# ë³€ìˆ˜ì™€ í•¨ê»˜ ì‹¤í–‰
sbkube workflow run quick-deploy --var env=staging --var debug=true

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/unit/utils/test_workflow_engine.py -v
```

## ğŸ“ ì˜ˆìƒ ê²°ê³¼

```bash
$ sbkube workflow run quick-deploy
ğŸš€ ì›Œí¬í”Œë¡œìš° 'quick-deploy' ì‹¤í–‰ ì‹œì‘
â­ï¸  ë‹¨ê³„ ê±´ë„ˆë›°ê¸°: prepare (ì¡°ê±´ ë¶ˆë§Œì¡±)
ğŸ”„ ë³‘ë ¬ ì‹¤í–‰: deploy (2ê°œ ì•±)
  ğŸ“¦ ë°°í¬ ì¤‘: frontend
  ğŸ“¦ ë°°í¬ ì¤‘: backend
âœ… ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: deploy (2/2)
âœ… ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ

$ sbkube workflow list
ğŸ”„ ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì´ë¦„         â”‚ ì„¤ëª…                    â”‚ ë‹¨ê³„ ìˆ˜â”‚ ë²„ì „   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ quick-deploy â”‚ ë¹ ë¥¸ ë°°í¬ (ìºì‹œ í™œìš©)   â”‚    2   â”‚  1.0   â”‚
â”‚ full-ci-cd   â”‚ ì „ì²´ CI/CD íŒŒì´í”„ë¼ì¸   â”‚    6   â”‚  1.0   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ ë‹¤ìŒ ë‹¨ê³„

ì´ ì‘ì—… ì™„ë£Œ í›„ ë‹¤ìŒ ì‘ì—…ìœ¼ë¡œ ì§„í–‰:
- `014-interactive-assistant-system.md` - ëŒ€í™”í˜• ì‚¬ìš©ì ì§€ì› ì‹œìŠ¤í…œ êµ¬í˜„